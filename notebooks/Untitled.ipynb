{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7255e016-5be7-407c-bec7-2cd6b049cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    prepare_model_for_int8_training,\n",
    "    PeftModelForCausalLM\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95dd6a67-1d6e-496c-a04a-065f75c169c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7499d34517a04e98bb17f254fd2f75d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48294a70b459424d987f05fd5b635e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer\n",
    "\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"hf-internal-testing/llama-tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
    "original_llama = AutoModelForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e86af377-568a-4965-a844-1fe11cee361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = PeftModelForCausalLM.from_pretrained(original_llama, '/home/jovyan/llama/peft_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff0164fd-a262-4cc0-8c0f-a37d2c8c2e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29871, 13]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\\n\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e01e2ba-d1a9-46ec-97a3-fabf4c665e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f877fa8-9338-4a69-a262-d2e85eb0c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_CONFIG = {\n",
    "    \"r\": 12,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc7996c7-56f0-4712-b168-7ddbb7787d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(**LORA_CONFIG)\n",
    "# model = prepare_model_for_int8_training(model, use_gradient_checkpointing=False)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d6dc3c5-7897-43d4-84ca-0901751666bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_weights = torch.load(\"trained/checkpoint-8000/merged_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69caa65f-3049-4b9a-af03-c28d678434b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(lora_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01039bd7-9726-45c9-a152-e7a05798268a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_A): Linear(in_features=4096, out_features=12, bias=False)\n",
       "                (lora_B): Linear(in_features=12, out_features=4096, bias=False)\n",
       "              )\n",
       "              (k_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_A): Linear(in_features=4096, out_features=12, bias=False)\n",
       "                (lora_B): Linear(in_features=12, out_features=4096, bias=False)\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_A): Linear(in_features=4096, out_features=12, bias=False)\n",
       "                (lora_B): Linear(in_features=12, out_features=4096, bias=False)\n",
       "              )\n",
       "              (o_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_A): Linear(in_features=4096, out_features=12, bias=False)\n",
       "                (lora_B): Linear(in_features=12, out_features=4096, bias=False)\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82a3c881-a731-408c-a453-5a0ebabd2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"peft_trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ec0d69-ecc2-42cd-877b-0e1b96e977e8",
   "metadata": {},
   "source": [
    "## Fine-tuned llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67598c2c-e9ce-439d-a5a6-6a47a449a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"\"\"Это правило не везде, однако, могло быть проведено с безусловной последовательностью; практика вызывала частные отклонения, создавала те или иные комбинации. Если известное божество считалось главным божеством известного государства, то государство признавало иногда (как в Афинах) вместе с тем и некоторые другие культы; наряду с этими общегосударственными культами существовали и отдельные культы государственных делений (например, афинских демов), и культы частноправового значения (например, домашние или семейные), а также культы частных обществ или лиц.\n",
    "Вопрос: Везде ли правило могло быть проведено с безусловной последовательностью?\n",
    "Ответ (да/нет):\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1ac8f40-1ffe-4843-8ed3-79f6accf396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(inp, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0130a93b-b3f3-4ac4-95ea-3d78bb959e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids=inputs.input_ids, \n",
    "                        max_new_tokens=100,\n",
    "                        temperature=0.98,\n",
    "                        repetition_penalty=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "134c0e2d-696a-4f94-803c-62a7be0725d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf\n"
     ]
    }
   ],
   "source": [
    "print(\"sdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a92ca1a3-7dd7-42c9-88a8-3c2f8a195cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tokenizer.batch_decode(output, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "773bf965-68eb-4c9b-bb8d-caf1fe41469e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>По данным экспертов, в Ялте по итогам 25 апреля текущего года по сравнению с предыдущим годом аренда жилья в среднем подешевела на 35 процентов, до 39,4 тысячи рублей в месяц. Вторым в списке курортных городов с наиболее подешевевшей арендой специалисты назвали Калининград со снижением на 16 процентов, до 19,4 тысячи рублей в месяц. Замкнул тройку Севастополь с отрицательной динамикой - за год цены выросли почти на 80 процентов, до 70,5 тысяч рублей в месяц.\n",
      "Всего в рейтинге \"Коммерсанта\" вошло 20 крупнейших российских курортов: Сочи (№ 1), Анапа (№ 2), Новороссийск (№ 3), Геленджик (№ 4\n"
     ]
    }
   ],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3ad09-8fbd-4d67-ba64-98fdb1ab9b37",
   "metadata": {},
   "source": [
    "## ruGpt3large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "566c6b4a-ef64-4795-80b4-bc2eb06b695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "gpt_model_name_or_path = \"ai-forever/rugpt3large_based_on_gpt2\"\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(gpt_model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ced435f6-4e69-4a4a-b034-82925a0e2d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4408, 3761, 14971, 16, 282, 34471, 464, 334, 8872, 2706, 4238, 16642, 779, 334, 7413, 281, 49509, 12260, 25581, 12712, 282, 11099, 46698, 555, 309, 6603, 7540], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer(\"По данным экспертов, в Ялте по итогам 25 апреля текущего года по сравнению с предыдущим годом аренда жилья в среднем подешевела на 35 процентов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126311a-a88d-43f3-8e29-cd94736e8104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c7544-4564-464f-86db-e3ce44de8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = GPT2LMHeadModel.from_pretrained(gpt_model_name_or_path).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1321410-bb14-46c6-aa92-ddea65c8a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По данным экспертов, в Ялте по итогам 25 апреля текущего года по сравнению с предыдущим годом аренда жилья в среднем подешевела на 35 процентов, до 39,4 тысячи рублей в месяц. Вторым в списке курортных городов с наиболее подешевевшей арендой специалисты назвали Калининград со снижением на 16 процентов, до 19,4 тысячи рублей в месяц. Замкнул тройку Севастополь с отрицательной динамикой - минус 15 процентных пунктов и 13 тысяч за квадратный метр жилой площади соответственно (в Симферополе жилье подорожало всего лишь чуть более чем вдвое).<s>\n",
      "В Москве задержали мужчину из-за нападения грабителя банка Полиция задержала подозреваемого во взяточничестве жителя Москвы после того как он попытался ограбить банк «Солидарность». Об этом сообщает РИА Новости. По словам представителя пресс службы столичного главка МВД Андрея Галиакберова, задержанный был задержан при попытке ограбления отделения Сбербанка России №\n"
     ]
    }
   ],
   "source": [
    "input_ids = gpt_tokenizer.encode(inp, return_tensors=\"pt\").cpu()\n",
    "out = gpt_model.generate(input_ids.cpu(), \n",
    "                         max_new_tokens=100,\n",
    "                         temperature=0.98,\n",
    "                         repetition_penalty=1.7)\n",
    "\n",
    "generated_text = list(map(gpt_tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d0c60-8092-417f-9d1d-044be025c699",
   "metadata": {},
   "source": [
    "## Original llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "583aa75c-99fe-431d-b744-e5729beb066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(inp, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92cd69c1-e63f-48e7-8356-58afc07387da",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = original_llama.generate(input_ids=inputs.input_ids, \n",
    "                                 max_new_tokens=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c4ba3e4-fb94-4b01-825e-2623ef255a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tokenizer.batch_decode(output, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95a1136d-19a5-43c3-9934-b9740ad3e985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Это правило не везде, однако, могло быть проведено с безусловной последовательностью; практика вызывала частные отклонения, создавала те или иные комбинации. Если известное божество считалось главным божеством известного государства, то государство признавало иногда (как в Афинах) вместе с тем и некоторые другие культы; наряду с этими общегосударственными культами существовали и отдельные культы государственных делений (например, афинских демов), и культы частноправового значения (например, домашние или семейные), а также культы частных обществ или лиц.\n",
      "Вопрос: Везде ли правило могло быть проведено с безусловной последовательностью?\n",
      "Ответ (да/нет): Нет\n"
     ]
    }
   ],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef74335-1bea-48e9-8d04-70e44c4dcf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
