{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5671f6-83f2-4b9b-b3d4-85c58fbe4df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 1))\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-_36ndw_z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-_36ndw_z\n",
      "  Resolved https://github.com/huggingface/transformers to commit d04ec99bec8a0b432fc03ed60cea9a1a20ebaf3c\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: datasets in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.11.0)\n",
      "Requirement already satisfied: jsonlines in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: zstandard in /home/user/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.19.0)\n",
      "Requirement already satisfied: peft in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: accelerate in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.18.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (0.38.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/conda/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user/conda/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (2022.10.31)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/conda/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/conda/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user/conda/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (4.64.1)\n",
      "Requirement already satisfied: filelock in /home/user/conda/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: requests in /home/user/conda/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from transformers==4.29.0.dev0->-r requirements.txt (line 1)) (0.13.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/user/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 2)) (10.0.1)\n",
      "Requirement already satisfied: multiprocess in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 2)) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/user/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 2)) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: pandas in /home/user/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 2)) (2023.4.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/user/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 2)) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/user/conda/lib/python3.9/site-packages (from jsonlines->-r requirements.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: psutil in /home/user/conda/lib/python3.9/site-packages (from peft->-r requirements.txt (line 5)) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/user/conda/lib/python3.9/site-packages (from peft->-r requirements.txt (line 5)) (2.0.0.dev20230205+cu117)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.29.0.dev0->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.9/site-packages (from requests->transformers==4.29.0.dev0->-r requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.9/site-packages (from requests->transformers==4.29.0.dev0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/conda/lib/python3.9/site-packages (from requests->transformers==4.29.0.dev0->-r requirements.txt (line 1)) (1.26.14)\n",
      "Requirement already satisfied: networkx in /home/user/conda/lib/python3.9/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 5)) (3.0)\n",
      "Requirement already satisfied: pytorch-triton==2.0.0+0d7e753227 in /home/user/conda/lib/python3.9/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 5)) (2.0.0+0d7e753227)\n",
      "Requirement already satisfied: sympy in /home/user/conda/lib/python3.9/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 5)) (1.11.1)\n",
      "Requirement already satisfied: cmake in /home/user/conda/lib/python3.9/site-packages (from pytorch-triton==2.0.0+0d7e753227->torch>=1.13.0->peft->-r requirements.txt (line 5)) (3.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/user/conda/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/conda/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/user/conda/lib/python3.9/site-packages (from sympy->torch>=1.13.0->peft->-r requirements.txt (line 5)) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00216ea5-eb8b-4029-b75c-09031c970af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d09df0-8171-4736-b1e3-46db7e684cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"hf-internal-testing/llama-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad546fe6-15a0-4ddc-888e-0c7a56ade17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: rulm/default\n",
      "Found cached dataset rulm (/home/jovyan/.cache/huggingface/datasets/IlyaGusev___rulm/default/0.0.1/c94da05286e8839c1219f9a5061c630709a487fb298427a6f5a73ee0fe2cd2cb)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"./chunk_dataset\")\n",
    "val_dataset = load_dataset(\"IlyaGusev/rulm\", split=\"validation[:10%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87bff9dc-2783-41f7-a9b7-2f22a8f64402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af748bd-b623-4751-bad3-f9d55da0520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(prompt, add_eos_token=True):\n",
    "    result = tokenizer(prompt)\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f097ec21-20f4-4420-8e6b-6d912f8c97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def chunk_examples(examples, max_length):\n",
    "    input_ids_chunks = []\n",
    "    attention_mask_chunks = []\n",
    "    # print(len(examples[\"input_ids\"]))\n",
    "    input_ids = list(chain(*examples[\"input_ids\"]))\n",
    "    attention_mask = list(chain(*examples[\"attention_mask\"]))\n",
    "    input_ids_chunks.extend(\n",
    "        [\n",
    "            input_ids[i : i + max_length]\n",
    "            for i in range(0, len(input_ids), max_length)\n",
    "        ]\n",
    "    )\n",
    "    attention_mask_chunks.extend(\n",
    "        [\n",
    "            attention_mask[i : i + max_length]\n",
    "            for i in range(0, len(attention_mask), max_length)\n",
    "        ]\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": input_ids_chunks,\n",
    "        \"attention_mask\": attention_mask_chunks,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08d64a4-2847-44f6-9c0b-d667f11898fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset):\n",
    "    tokenized_dataset = dataset.map(lambda x: tokenize(x['text']),\n",
    "                                    num_proc=16, remove_columns=[\"meta\"])\n",
    "    chunk_dataset = tokenized_dataset.map(lambda x: chunk_examples(x, 512), batched=True, batch_size=100,\n",
    "                                          num_proc=16, remove_columns=tokenized_dataset.column_names)\n",
    "    return tokenized_dataset, chunk_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f2d9639-e97e-4fdf-801c-25cc7a3fdba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/IlyaGusev___rulm/default/0.0.1/c94da05286e8839c1219f9a5061c630709a487fb298427a6f5a73ee0fe2cd2cb/cache-f418d707dbed0c01_*_of_00016.arrow\n",
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/IlyaGusev___rulm/default/0.0.1/c94da05286e8839c1219f9a5061c630709a487fb298427a6f5a73ee0fe2cd2cb/cache-826a7ac955c9b816_*_of_00016.arrow\n"
     ]
    }
   ],
   "source": [
    "_, chunk_val_dataset = prepare_dataset(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0505ee-8625-4443-bd0f-08dcc41ff5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd5e56c-5227-4285-a4e2-eec6a49512bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /home/jovyan/.imgenv-zealous-villani-0 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//download.openmmlab.com/mmcv/dist/cu117/torch1.11.0/index.html')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.18.215.105'), PosixPath('80'), PosixPath('tcp')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('22'), PosixPath('tcp'), PosixPath('//172.18.110.92')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sr002-mt/notebook/ai0002258-00001/zealous-villani')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('Europe/Moscow')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('80'), PosixPath('tcp'), PosixPath('//172.18.110.92')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('443'), PosixPath('tcp'), PosixPath('//172.18.0.1')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('0.0.33'), PosixPath('cr.msk.sbercloud.ru/aicloud-base-images/cuda11.7-pt2')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//download.pytorch.org/whl/torch_stable.html')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.18.215.105'), PosixPath('22'), PosixPath('tcp')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('cbfa7664-374246'), PosixPath('cr.msk.sbercloud.ru/aicloud-jupyter-test/jupyter-cuda11.7-pt2')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/jovyan/.imgenv-zealous-villani-0/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632dbb2c1883431aafdcd52a9f017c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig #, prepare_model_for_int8_training\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\", load_in_8bit=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "358ec647-3b22-46ce-83dc-ed50424cf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_usage():\n",
    "    used, total = torch.cuda.mem_get_info()\n",
    "    free = ((used / 1024) / 1024) / 1024\n",
    "    total = ((total / 1024) / 1024) / 1024\n",
    "    print(f\"{total - free} gigs out of {total} is used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d13eba9-42de-45cb-b281-7da5c6675ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6738415616"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eacdb700-a1e9-4640-9c67-70b608f261ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = {\n",
    "        \"r\": 8,\n",
    "        \"lora_alpha\": 16,\n",
    "        \"lora_dropout\": 0.05,\n",
    "        \"bias\": \"none\",\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
    "        \"task_type\": \"CAUSAL_LM\"\n",
    "    }\n",
    "\n",
    "lora_config = LoraConfig(**lc)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1154c36f-9c41-44e4-bfd7-54e27c7247fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6738415616"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94c13c51-ff06-40ea-a581-bb5bf90e96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = len(list(filter(lambda p: p.requires_grad, model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9e482e9-6b7b-4ab8-9539-bd82123e8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.Size([32000, 4096])\n",
      "model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.0.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.0.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.1.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.1.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.2.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.2.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.3.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.3.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.4.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.4.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.5.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.5.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.6.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.6.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.7.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.7.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.8.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.8.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.9.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.9.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.10.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.10.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.11.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.11.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.12.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.12.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.13.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.13.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.14.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.14.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.15.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.15.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.16.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.16.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.17.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.17.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.18.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.18.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.19.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.19.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.20.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.20.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.21.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.21.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.22.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.22.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.23.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.23.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.24.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.24.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.25.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.25.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.26.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.26.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.27.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.27.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.28.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.28.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.29.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.29.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.30.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.30.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])\n",
      "model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])\n",
      "model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])\n",
      "model.layers.31.input_layernorm.weight torch.Size([4096])\n",
      "model.layers.31.post_attention_layernorm.weight torch.Size([4096])\n",
      "model.norm.weight torch.Size([4096])\n",
      "lm_head.weight torch.Size([32000, 4096])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        print(n, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a29d29a-cd6a-4ae9-ab73-d2572dd268f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8aab98c0-38cd-47f8-b0bd-f71de4816cc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "iterable unpacking cannot be used in comprehension (2366213081.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[64], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    params = sum([*np.prod(p.size()) for p in model_parameters])\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m iterable unpacking cannot be used in comprehension\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([*np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a711416e-ce67-4c8c-9865-00b83a549e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.404052734375 gigs out of 39.58709716796875 is used\n"
     ]
    }
   ],
   "source": [
    "mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd9137d1-fa35-443b-8007-096b1d2ddbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ec76ce-ec63-466c-8512-173508eef3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def get_gpu_objects():\n",
    "    objs = []\n",
    "\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                if str(obj.device) == \"cuda:0\":\n",
    "                    objs.append(obj)\n",
    "        except:\n",
    "            pass\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa49f510-604c-48a9-89d4-bd3e879d1cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:284: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_objs = get_gpu_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de94a2b2-7e1f-49db-89fd-d357286a3e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.113037109375 gigs out of 39.58709716796875 is used\n"
     ]
    }
   ],
   "source": [
    "mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "704e5818-300d-4d54-afd4-8a3a119e0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "X = torch.tensor([dataset[i][\"input_ids\"] for i in range(bs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ed4c856-5a04-47d2-af74-640dd66fcf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be32fdda-3dd5-42b4-a00e-59775a4ca897",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46919df8-5134-4a1f-98ad-a2dd7b3fa023",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_X_objs = get_gpu_objects()\n",
    "# set(model_and_X_objs) - set(model_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c7b2ed8-5f45-4f88-8559-c686aaa07ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.111083984375 gigs out of 39.58709716796875 is used\n"
     ]
    }
   ],
   "source": [
    "mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "337817af-6208-4d12-8c7e-5c4014cbbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.forward(X, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8414a523-279e-49ae-b21b-f48a7b262d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.modeling_llama.LlamaForCausalLM"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "141e717f-4a27-4414-92a7-4146b2d1db9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 32000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3afb2712-ad93-40d0-a018-6f05ff69be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_inference_objs = get_gpu_objects()\n",
    "new_objs = set(after_inference_objs) - set(model_and_X_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e010cc04-3ff4-494a-9754-b51fe0e5033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adeab846-b155-48f9-b91a-a8ad56a62cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 32000])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 1])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 512, 4096])\n",
      "torch.Size([1, 32, 512, 512])\n",
      "torch.Size([1, 512, 128])\n",
      "torch.Size([1, 512, 11008])\n"
     ]
    }
   ],
   "source": [
    "for no in new_objs:\n",
    "    print(no.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b2c1863-f8b2-4750-901c-fb1cd95f93e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.564208984375 gigs out of 39.58709716796875 is used\n"
     ]
    }
   ],
   "source": [
    "mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79c67eb4-5577-40e4-b7b5-5602e3111b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 32000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3515a50-cc2d-4aee-a880-7285e4c259f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "487c52fe-6ca8-4bb0-942c-b38f77ad2e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[-12.7782, -28.6373,   0.9082,  ...,  -7.6488,  -8.5625,  -7.6831],\n",
       "         [ -7.3367, -16.1066,   0.3829,  ...,  -2.2448,  -3.9622,  -2.7864],\n",
       "         [ -3.2643,  -4.9375,  -0.5947,  ...,  -0.8401,  -3.1155,  -1.8175],\n",
       "         ...,\n",
       "         [ -0.1562,  -3.6233,  12.5931,  ...,   3.1760,   3.3542,   4.4769],\n",
       "         [ -8.6087, -20.0140,   1.4349,  ...,  -2.2611,  -4.9424,  -1.8318],\n",
       "         [ -4.8588, -10.9607,   4.6263,  ...,  -1.3441,  -4.0876,  -3.1225]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>), past_key_values=None, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d019389f-1e87-4491-8b74-b3fb272e3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.564208984375 gigs out of 39.58709716796875 is used\n"
     ]
    }
   ],
   "source": [
    "mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "535926cd-50ca-49f6-9f3a-6328c7daf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0af92742-2986-4527-853d-beee8ae7c8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.542724609375 gigs out of 39.58709716796875 is used\n"
     ]
    }
   ],
   "source": [
    "mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0889ccd-bb4c-4f29-9a7f-0b1255781774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9871322-2204-41aa-bb79-a88dbae9b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.base_model.model.model.layers[0].mlp.gate_proj.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e65a43e-3be2-4ef4-954b-5a51c1f33af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for n, p in model.named_parameters():\n",
    "    if p.grad:\n",
    "        print(\"kek\")\n",
    "        total_parameters += math.prod([s for s in p.grad])\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6eb3a9f0-5aff-4f0e-bcdf-22de5910ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_params = 0\n",
    "for i in y.past_key_values:\n",
    "    for j in i:\n",
    "        p = 1\n",
    "        for k in j.shape:\n",
    "            p *= k\n",
    "        y_params += p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "058400b9-8d22-489c-930c-10f919032563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((y_params * 32) / 8) / 1024) / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bb008c2-024f-4647-aea7-bf9f00243856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 512, 128])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b1d8d7b-7cc7-492f-9067-fa29738807b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 32000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1717a295-664e-409c-b345-de7de36b41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # \"trainer\": {\n",
    "    #     \"evaluation_strategy\": \"steps\",\n",
    "    #     \"per_device_train_batch_size\": 16,\n",
    "    #     \"per_device_eval_batch_size\": 16,\n",
    "    #     \"gradient_accumulation_steps\": 8,\n",
    "    #     \"eval_steps\": 75,\n",
    "    #     \"save_steps\": 75,\n",
    "    #     \"logging_steps\": 5,\n",
    "    #     \"learning_rate\": 0.0003,\n",
    "    #     \"num_train_epochs\": 3,\n",
    "    #     \"lr_scheduler_type\": \"cosine\",\n",
    "    #     \"warmup_steps\": 50,\n",
    "    #     \"fp16\": true,\n",
    "    #     \"bf16\": false,\n",
    "    #     \"torch_compile\": false,\n",
    "    #     \"optim\": \"adamw_torch\"\n",
    "    # },\n",
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=75,\n",
    "    eval_steps=75,\n",
    "    warmup_steps=50,\n",
    "    logging_steps=5,\n",
    "\n",
    "    gradient_accumulation_steps=8,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    learning_rate=0.0003,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "\n",
    "    per_device_eval_batch_size=2,\n",
    "    per_device_train_batch_size=2,\n",
    "\n",
    "    # fp16=True,\n",
    "    # bf16=False,\n",
    "    torch_compile=False,\n",
    "    optim=\"adamw_torch\",\n",
    "\n",
    "    logging_dir='./logs',\n",
    "    output_dir='./trained',\n",
    "    \n",
    "    no_cuda=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=chunk_val_dataset,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9060ed-c942-40eb-aa2c-75e27c378ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f05b1295-a413-489d-b61e-77ce600c790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "117aa9f9-c7dd-42de-acfe-b8dc675f6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a26930ec-159e-4389-bb47-7ca2af89d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd7aef67-1293-4640-850a-78e828b51720",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_collator([dataset[0], dataset[1]])['input_ids'].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b342f233-17f8-4c02-b066-d52e0600b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ids = cuda_m(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed2beb7d-5d2c-43ac-ae41-bd2adf7782c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ids.logits.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cad68dfe-d2f8-4b3b-8126-0b2d522884f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.CausalLMOutputWithPast"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(generate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9389e9a5-d5e3-4439-ae4e-6c15d20f8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "del generate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bd1136f-e8cb-4917-86d9-10eb5f9392ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04b4bf67-4d6a-400f-b9e9-85ab6ade7a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ids.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
